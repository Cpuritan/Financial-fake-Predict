{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_wy = pd.read_csv(r'./文娱行业_full.csv')\n",
    "df_ct = pd.read_csv(r'./传统行业_full.csv')\n",
    "df_fw = pd.read_csv(r'./服务业_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wy = ['REVENUE', 'COGS', 'PREPAYMENT', 'OTH_PAYABLE', 'C_INF_FR_FINAN_A',\n",
    "    'SURPLUS_RESER',  'T_NCA',\n",
    "    'MINORITY_GAIN', 'END_DATE_REP', 'RETAINED_EARNINGS', 'SELL_EXP',\n",
    "    'PUBLISH_DATE', 'T_LIAB']#, 'OTH_NCA''C_FR_OTH_INVEST_A',\n",
    "wy1= ['A_J_INVEST_INCOME', 'DEFER_TAX_LIAB', 'DEFER_TAX_ASSETS', 'CIP',\n",
    "       'COGS', 'SURPLUS_RESER', 'SELL_EXP', 'T_PROFIT', 'T_CL',\n",
    "       'C_PAID_INVEST']\n",
    "ct = ['REVENUE', 'COGS', 'PREPAYMENT', 'OTH_PAYABLE', 'C_INF_FR_FINAN_A',\n",
    "    'SURPLUS_RESER', 'C_FR_OTH_INVEST_A', 'T_NCA', 'OTH_NCA',\n",
    "    'MINORITY_GAIN', 'END_DATE_REP', 'RETAINED_EARNINGS', 'SELL_EXP',\n",
    "    'PUBLISH_DATE', 'T_LIAB']\n",
    "ct1= ['PAYROLL_PAYABLE', 'MINORITY_INT', 'OTH_RECEIV', 'T_LIAB_EQUITY',\n",
    "       'AVAIL_FOR_SALE_FA', 'ADVANCE_RECEIPTS', 'DEFER_TAX_LIAB',\n",
    "       'C_PAID_INVEST', 'TAXES_PAYABLE', 'FIXED_ASSETS']\n",
    "fw = ['REVENUE', 'COGS', 'PREPAYMENT', 'OTH_PAYABLE', 'C_INF_FR_FINAN_A',\n",
    "    'SURPLUS_RESER', 'T_NCA', 'OTH_NCA',\n",
    "    'MINORITY_GAIN', 'END_DATE_REP', 'RETAINED_EARNINGS', 'SELL_EXP',\n",
    "    'PUBLISH_DATE', 'T_LIAB']#, 'C_FR_OTH_INVEST_A'\n",
    "fw1= ['OTH_PAYABLE', 'FOREX_EFFECTS', 'N_CE_BEG_BAL', 'COGS',\n",
    "       'C_PAID_FOR_DEBTS', 'C_INF_FR_INVEST_A', 'CIP', 'T_LIAB', 'OTH_NCA',\n",
    "       'ADMIN_EXP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_wy[wy]\n",
    "df2 = df_ct[ct]\n",
    "df3 = df_fw[fw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 stacking预测其他产业（除制造业）造假概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pred(x):\n",
    "    u=[]\n",
    "    for i in x:\n",
    "        if i>0.4:\n",
    "            u.append(1)\n",
    "        else:\n",
    "            u.append(0)\n",
    "    return np.array(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文娱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[12:19:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5827586206896552\n",
      "auc is 0.5126436781609195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "base model (m_xgb & m_clf)\n",
      "[12:19:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5816091954022988\n",
      "auc is 0.6114942528735632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 2\n",
      "base model (m_xgb & m_clf)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[12:19:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5793103448275863\n",
      "auc is 0.7137931034482758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[12:19:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n",
      "base model (m_xgb & m_clf)\n",
      "[12:19:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5816091954022988\n",
      "auc is 0.603448275862069\n",
      "[12:19:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 4\n",
      "base model (m_xgb & m_clf)\n",
      "[12:19:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5804597701149424\n",
      "auc is 0.6298850574712643\n",
      "[12:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 5\n",
      "base model (m_xgb & m_clf)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[12:19:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5758620689655173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.496551724137931\n",
      "[12:19:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6\n",
      "base model (m_xgb & m_clf)\n",
      "[12:19:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5850574712643678\n",
      "auc is 0.7137931034482758\n",
      "[12:19:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.07142857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "h=0\n",
    "for i in range(20):\n",
    "    \n",
    "    x = df_wy[wy]\n",
    "    y = df_wy['FLAG']\n",
    "\n",
    "    # 划分数据集&SMOTE采样\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=202)\n",
    "    from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "    smo = SMOTE()\n",
    "    X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "    m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=0.5,reg_alpha=1.7,reg_lambda=0.8)\n",
    "    m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)#)\n",
    "    models = [m_xgb,m_clf]\n",
    "\n",
    "    print('base model (m_xgb & m_clf)')\n",
    "    for model in models:\n",
    "        model.fit(X_smo, y_smo)\n",
    "        pred = model.predict(x_test)\n",
    "        print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "    sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "    sclf.fit(X_smo, y_smo)\n",
    "    pred = sclf.predict(x_test)\n",
    "    \n",
    "    if metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test)>0.07:\n",
    "        print(metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test))\n",
    "        break\n",
    "    else:\n",
    "        h=h+1\n",
    "        print(\"h=\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stacking_wy_0.07']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sclf,\"stacking_wy_0.07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用模型\n",
    "import joblib\n",
    "model1=joblib.load(\"stacking_wy_0.07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_pred=pd.read_csv(r'./pre_data_wy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>COGS</th>\n",
       "      <th>PREPAYMENT</th>\n",
       "      <th>OTH_PAYABLE</th>\n",
       "      <th>C_INF_FR_FINAN_A</th>\n",
       "      <th>SURPLUS_RESER</th>\n",
       "      <th>T_NCA</th>\n",
       "      <th>MINORITY_GAIN</th>\n",
       "      <th>END_DATE_REP</th>\n",
       "      <th>RETAINED_EARNINGS</th>\n",
       "      <th>SELL_EXP</th>\n",
       "      <th>PUBLISH_DATE</th>\n",
       "      <th>T_LIAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.380000e+11</td>\n",
       "      <td>1.020000e+11</td>\n",
       "      <td>8.793025e+09</td>\n",
       "      <td>2.817423e+09</td>\n",
       "      <td>6.090000e+11</td>\n",
       "      <td>1.078100e+10</td>\n",
       "      <td>1.764400e+11</td>\n",
       "      <td>3.380048e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>1.130000e+11</td>\n",
       "      <td>9.732335e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>3.630000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.105998e+10</td>\n",
       "      <td>9.955307e+09</td>\n",
       "      <td>9.202931e+06</td>\n",
       "      <td>2.320320e+08</td>\n",
       "      <td>4.374251e+08</td>\n",
       "      <td>3.501876e+08</td>\n",
       "      <td>2.710512e+09</td>\n",
       "      <td>2.101465e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>1.495135e+09</td>\n",
       "      <td>2.506577e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>2.151629e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.710729e+08</td>\n",
       "      <td>4.310213e+08</td>\n",
       "      <td>1.268360e+07</td>\n",
       "      <td>7.578789e+07</td>\n",
       "      <td>1.780200e+08</td>\n",
       "      <td>2.100749e+07</td>\n",
       "      <td>9.614450e+08</td>\n",
       "      <td>-8.624743e+05</td>\n",
       "      <td>7</td>\n",
       "      <td>3.874235e+08</td>\n",
       "      <td>2.395610e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>3.065691e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.704211e+09</td>\n",
       "      <td>2.217208e+09</td>\n",
       "      <td>1.084796e+07</td>\n",
       "      <td>1.422322e+08</td>\n",
       "      <td>7.188483e+08</td>\n",
       "      <td>2.357012e+08</td>\n",
       "      <td>1.100421e+09</td>\n",
       "      <td>3.398830e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>9.668408e+08</td>\n",
       "      <td>8.657921e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>1.106384e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.204576e+10</td>\n",
       "      <td>4.629241e+10</td>\n",
       "      <td>3.898288e+08</td>\n",
       "      <td>1.792343e+09</td>\n",
       "      <td>3.791859e+08</td>\n",
       "      <td>2.140635e+08</td>\n",
       "      <td>7.133217e+09</td>\n",
       "      <td>2.129295e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>7.752266e+09</td>\n",
       "      <td>3.055404e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>1.845486e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>9.718632e+08</td>\n",
       "      <td>7.715696e+08</td>\n",
       "      <td>1.351586e+07</td>\n",
       "      <td>6.268764e+07</td>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>1.175569e+08</td>\n",
       "      <td>7.369098e+08</td>\n",
       "      <td>-2.103888e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>7.909683e+08</td>\n",
       "      <td>3.533841e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>3.116228e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3.874468e+09</td>\n",
       "      <td>2.494694e+09</td>\n",
       "      <td>1.644366e+08</td>\n",
       "      <td>1.507342e+08</td>\n",
       "      <td>2.762278e+08</td>\n",
       "      <td>5.133836e+07</td>\n",
       "      <td>8.729256e+07</td>\n",
       "      <td>-1.510847e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>8.303525e+08</td>\n",
       "      <td>9.607590e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>6.441541e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2.527155e+09</td>\n",
       "      <td>1.888450e+09</td>\n",
       "      <td>1.781445e+07</td>\n",
       "      <td>1.635687e+08</td>\n",
       "      <td>8.420000e+07</td>\n",
       "      <td>1.051035e+07</td>\n",
       "      <td>9.700380e+08</td>\n",
       "      <td>2.525531e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>1.707384e+08</td>\n",
       "      <td>3.884044e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>9.007368e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>3.528526e+09</td>\n",
       "      <td>2.288284e+09</td>\n",
       "      <td>1.673907e+08</td>\n",
       "      <td>1.768201e+08</td>\n",
       "      <td>9.680000e+07</td>\n",
       "      <td>4.166492e+07</td>\n",
       "      <td>5.963636e+08</td>\n",
       "      <td>-1.848165e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>3.854472e+08</td>\n",
       "      <td>8.884024e+08</td>\n",
       "      <td>7</td>\n",
       "      <td>1.417799e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1.543400e+08</td>\n",
       "      <td>6.114716e+07</td>\n",
       "      <td>3.575905e+05</td>\n",
       "      <td>1.003951e+08</td>\n",
       "      <td>3.644870e+08</td>\n",
       "      <td>1.855032e+07</td>\n",
       "      <td>1.476354e+07</td>\n",
       "      <td>7.150261e+05</td>\n",
       "      <td>7</td>\n",
       "      <td>1.039904e+08</td>\n",
       "      <td>1.630135e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>5.238359e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          REVENUE          COGS    PREPAYMENT   OTH_PAYABLE  C_INF_FR_FINAN_A  \\\n",
       "0    1.380000e+11  1.020000e+11  8.793025e+09  2.817423e+09      6.090000e+11   \n",
       "1    1.105998e+10  9.955307e+09  9.202931e+06  2.320320e+08      4.374251e+08   \n",
       "2    5.710729e+08  4.310213e+08  1.268360e+07  7.578789e+07      1.780200e+08   \n",
       "3    3.704211e+09  2.217208e+09  1.084796e+07  1.422322e+08      7.188483e+08   \n",
       "4    5.204576e+10  4.629241e+10  3.898288e+08  1.792343e+09      3.791859e+08   \n",
       "..            ...           ...           ...           ...               ...   \n",
       "377  9.718632e+08  7.715696e+08  1.351586e+07  6.268764e+07      8.000000e+06   \n",
       "378  3.874468e+09  2.494694e+09  1.644366e+08  1.507342e+08      2.762278e+08   \n",
       "379  2.527155e+09  1.888450e+09  1.781445e+07  1.635687e+08      8.420000e+07   \n",
       "380  3.528526e+09  2.288284e+09  1.673907e+08  1.768201e+08      9.680000e+07   \n",
       "381  1.543400e+08  6.114716e+07  3.575905e+05  1.003951e+08      3.644870e+08   \n",
       "\n",
       "     SURPLUS_RESER         T_NCA  MINORITY_GAIN  END_DATE_REP  \\\n",
       "0     1.078100e+10  1.764400e+11   3.380048e+08             7   \n",
       "1     3.501876e+08  2.710512e+09   2.101465e+07             7   \n",
       "2     2.100749e+07  9.614450e+08  -8.624743e+05             7   \n",
       "3     2.357012e+08  1.100421e+09   3.398830e+06             7   \n",
       "4     2.140635e+08  7.133217e+09   2.129295e+08             7   \n",
       "..             ...           ...            ...           ...   \n",
       "377   1.175569e+08  7.369098e+08  -2.103888e+06             7   \n",
       "378   5.133836e+07  8.729256e+07  -1.510847e+06             7   \n",
       "379   1.051035e+07  9.700380e+08   2.525531e+06             7   \n",
       "380   4.166492e+07  5.963636e+08  -1.848165e+06             7   \n",
       "381   1.855032e+07  1.476354e+07   7.150261e+05             7   \n",
       "\n",
       "     RETAINED_EARNINGS      SELL_EXP  PUBLISH_DATE        T_LIAB  \n",
       "0         1.130000e+11  9.732335e+09             7  3.630000e+12  \n",
       "1         1.495135e+09  2.506577e+08             7  2.151629e+09  \n",
       "2         3.874235e+08  2.395610e+07             7  3.065691e+08  \n",
       "3         9.668408e+08  8.657921e+08             7  1.106384e+09  \n",
       "4         7.752266e+09  3.055404e+09             7  1.845486e+10  \n",
       "..                 ...           ...           ...           ...  \n",
       "377       7.909683e+08  3.533841e+07             7  3.116228e+08  \n",
       "378       8.303525e+08  9.607590e+08             7  6.441541e+08  \n",
       "379       1.707384e+08  3.884044e+08             7  9.007368e+08  \n",
       "380       3.854472e+08  8.884024e+08             7  1.417799e+09  \n",
       "381       1.039904e+08  1.630135e+07             7  5.238359e+07  \n",
       "\n",
       "[382 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wy_pred[wy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pred(x):\n",
    "    u=[]\n",
    "    for i in x:\n",
    "        if i>0.1:\n",
    "            u.append(1)\n",
    "        else:\n",
    "            u.append(0)\n",
    "    return np.array(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_wy_pred['FLAG'] = Pred(model1.predict_proba(df_wy_pred[wy])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_pred.to_csv(r'./PRED_wy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_wy_same_proba=sclf.predict_proba(df_wy_pred[wy])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_wy_dif_proba=sclf.predict_proba(df_wy_pred[wy1])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_proba = (3/4)*df_wy_dif_proba+(1/4)*df_wy_same_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.7422692 ,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.25075468, 0.7422692 , 0.00369131,\n",
       "       0.7422692 , 0.00369131, 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.9893326 , 0.7422692 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.9893326 ,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.7422692 , 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.25075468, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.7422692 , 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.9893326 ,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.7422692 , 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.7422692 , 0.7422692 , 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.9893326 ,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.00369131, 0.00369131, 0.7422692 ,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.25075468,\n",
       "       0.00369131, 0.00369131, 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.25075468, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.7422692 , 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.9893326 , 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.25075468,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.7422692 , 0.00369131,\n",
       "       0.00369131, 0.7422692 , 0.7422692 , 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131, 0.00369131, 0.00369131, 0.00369131,\n",
       "       0.00369131, 0.00369131], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wy_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 传统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[21:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6538461538461537\n",
      "auc is 0.7059829059829059\n",
      "[21:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 1\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6512820512820512\n",
      "auc is 0.6329059829059829\n",
      "[21:06:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 2\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.7337606837606837\n",
      "auc is 0.6311965811965812\n",
      "[21:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 3\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6504273504273504\n",
      "auc is 0.7213675213675214\n",
      "[21:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 4\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5679487179487179\n",
      "auc is 0.6269230769230769\n",
      "[21:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 5\n",
      "base model (m_xgb & m_clf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5636752136752137\n",
      "auc is 0.5884615384615385\n",
      "[21:06:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 6\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6478632478632479\n",
      "auc is 0.620940170940171\n",
      "[21:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 7\n",
      "base model (m_xgb & m_clf)\n",
      "[21:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5662393162393162\n",
      "auc is 0.6226495726495727\n",
      "[21:07:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 8\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6495726495726496\n",
      "auc is 0.6405982905982907\n",
      "[21:07:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6512820512820512\n",
      "auc is 0.7414529914529915\n",
      "[21:07:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6487179487179486\n",
      "auc is 0.6465811965811967\n",
      "[21:07:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 11\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6487179487179486\n",
      "auc is 0.7273504273504273\n",
      "[21:07:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 12\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6452991452991453\n",
      "auc is 0.5858974358974359\n",
      "[21:07:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 13\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5653846153846154\n",
      "auc is 0.5893162393162393\n",
      "[21:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 14\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5662393162393162\n",
      "auc is 0.6888888888888889\n",
      "[21:07:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6487179487179486\n",
      "auc is 0.6175213675213675\n",
      "[21:07:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 16\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5628205128205128\n",
      "auc is 0.5970085470085469\n",
      "[21:07:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 17\n",
      "base model (m_xgb & m_clf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5688034188034188\n",
      "auc is 0.6106837606837606\n",
      "[21:07:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 18\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6529914529914529\n",
      "auc is 0.6311965811965812\n",
      "[21:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 19\n",
      "base model (m_xgb & m_clf)\n",
      "[21:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.6521367521367522\n",
      "auc is 0.6260683760683761\n",
      "[21:07:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from sklearn import metrics\n",
    "h=0\n",
    "for i in range(20):\n",
    "    \n",
    "    x = df_ct[ct]\n",
    "    y = df_ct['FLAG']\n",
    "    \n",
    "    # 划分数据集&SMOTE采样\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=202)\n",
    "    from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "    smo = SMOTE()\n",
    "    X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "    m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=0.5,reg_alpha=1.7,reg_lambda=0.8)\n",
    "    m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)#)\n",
    "    models = [m_xgb,m_clf]\n",
    "\n",
    "    print('base model (m_xgb & m_clf)')\n",
    "    for model in models:\n",
    "        model.fit(X_smo, y_smo)\n",
    "        pred = model.predict(x_test)\n",
    "        print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "    sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "    sclf.fit(X_smo, y_smo)\n",
    "    pred = sclf.predict(x_test)\n",
    "    \n",
    "    if metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test)>0.17:\n",
    "        print(metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test))\n",
    "        break\n",
    "    else:\n",
    "        h=h+1\n",
    "        print(\"h=\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stacking_ct_0.16']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sclf,\"stacking_ct_0.16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct_pred=pd.read_csv(r'./pre_data_ct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>COGS</th>\n",
       "      <th>PREPAYMENT</th>\n",
       "      <th>OTH_PAYABLE</th>\n",
       "      <th>C_INF_FR_FINAN_A</th>\n",
       "      <th>SURPLUS_RESER</th>\n",
       "      <th>C_FR_OTH_INVEST_A</th>\n",
       "      <th>T_NCA</th>\n",
       "      <th>OTH_NCA</th>\n",
       "      <th>MINORITY_GAIN</th>\n",
       "      <th>END_DATE_REP</th>\n",
       "      <th>RETAINED_EARNINGS</th>\n",
       "      <th>SELL_EXP</th>\n",
       "      <th>PUBLISH_DATE</th>\n",
       "      <th>T_LIAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.680000e+11</td>\n",
       "      <td>2.350000e+11</td>\n",
       "      <td>9.779583e+10</td>\n",
       "      <td>3.847734e+10</td>\n",
       "      <td>1.230000e+11</td>\n",
       "      <td>7.082625e+10</td>\n",
       "      <td>8.177287e+09</td>\n",
       "      <td>2.910000e+11</td>\n",
       "      <td>9.107320e+09</td>\n",
       "      <td>1.625953e+10</td>\n",
       "      <td>7</td>\n",
       "      <td>9.535204e+10</td>\n",
       "      <td>9.044497e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>1.460000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.526091e+08</td>\n",
       "      <td>4.165185e+08</td>\n",
       "      <td>1.212854e+08</td>\n",
       "      <td>2.388671e+08</td>\n",
       "      <td>6.445931e+08</td>\n",
       "      <td>1.495191e+08</td>\n",
       "      <td>8.800000e+07</td>\n",
       "      <td>1.434297e+09</td>\n",
       "      <td>2.518367e+07</td>\n",
       "      <td>3.810302e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.440113e+08</td>\n",
       "      <td>1.050584e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>1.289555e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.731330e+09</td>\n",
       "      <td>2.044318e+09</td>\n",
       "      <td>1.043950e+08</td>\n",
       "      <td>6.491167e+08</td>\n",
       "      <td>1.919280e+09</td>\n",
       "      <td>1.797479e+09</td>\n",
       "      <td>1.469453e+08</td>\n",
       "      <td>3.269382e+09</td>\n",
       "      <td>1.645932e+09</td>\n",
       "      <td>4.190187e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>3.103787e+09</td>\n",
       "      <td>5.173622e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>8.575092e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.202084e+07</td>\n",
       "      <td>1.316892e+07</td>\n",
       "      <td>3.039000e+04</td>\n",
       "      <td>3.293226e+07</td>\n",
       "      <td>1.300000e+07</td>\n",
       "      <td>8.998898e+06</td>\n",
       "      <td>1.551102e+08</td>\n",
       "      <td>1.421271e+08</td>\n",
       "      <td>4.445534e+07</td>\n",
       "      <td>-5.844119e+04</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.656718e+08</td>\n",
       "      <td>1.640569e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>3.208891e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.893071e+09</td>\n",
       "      <td>1.443554e+09</td>\n",
       "      <td>4.754241e+07</td>\n",
       "      <td>2.857902e+08</td>\n",
       "      <td>8.178834e+08</td>\n",
       "      <td>8.592789e+06</td>\n",
       "      <td>1.085256e+08</td>\n",
       "      <td>7.193082e+08</td>\n",
       "      <td>3.300000e+07</td>\n",
       "      <td>7.965270e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.857507e+09</td>\n",
       "      <td>5.032299e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>3.537930e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>1.738004e+08</td>\n",
       "      <td>7.289600e+06</td>\n",
       "      <td>4.289913e+06</td>\n",
       "      <td>7.362868e+07</td>\n",
       "      <td>1.045188e+09</td>\n",
       "      <td>5.236093e+06</td>\n",
       "      <td>6.838826e+08</td>\n",
       "      <td>6.191922e+08</td>\n",
       "      <td>3.251840e+07</td>\n",
       "      <td>1.790444e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.173116e+07</td>\n",
       "      <td>7.354806e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>2.450958e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>5.045575e+08</td>\n",
       "      <td>3.329071e+08</td>\n",
       "      <td>3.766541e+06</td>\n",
       "      <td>3.293226e+07</td>\n",
       "      <td>2.727550e+07</td>\n",
       "      <td>1.388311e+07</td>\n",
       "      <td>2.586743e+08</td>\n",
       "      <td>1.054024e+08</td>\n",
       "      <td>2.394196e+06</td>\n",
       "      <td>2.167739e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>1.684488e+08</td>\n",
       "      <td>1.467520e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>3.988528e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>3.351035e+08</td>\n",
       "      <td>2.018895e+08</td>\n",
       "      <td>3.238091e+06</td>\n",
       "      <td>3.293226e+07</td>\n",
       "      <td>1.500000e+08</td>\n",
       "      <td>2.565213e+07</td>\n",
       "      <td>1.529137e+08</td>\n",
       "      <td>1.992412e+07</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>1.749893e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>1.886917e+08</td>\n",
       "      <td>4.395137e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>7.945696e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2.584064e+08</td>\n",
       "      <td>1.426508e+08</td>\n",
       "      <td>1.814436e+06</td>\n",
       "      <td>3.293226e+07</td>\n",
       "      <td>4.135000e+07</td>\n",
       "      <td>9.019362e+06</td>\n",
       "      <td>2.370000e+08</td>\n",
       "      <td>8.756340e+07</td>\n",
       "      <td>5.710999e+07</td>\n",
       "      <td>-9.074536e+05</td>\n",
       "      <td>7</td>\n",
       "      <td>7.441286e+07</td>\n",
       "      <td>8.008995e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>7.341945e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>7.738161e+08</td>\n",
       "      <td>5.556131e+08</td>\n",
       "      <td>1.774841e+06</td>\n",
       "      <td>3.254897e+07</td>\n",
       "      <td>2.708759e+08</td>\n",
       "      <td>1.938591e+07</td>\n",
       "      <td>1.870351e+08</td>\n",
       "      <td>4.039975e+08</td>\n",
       "      <td>1.225751e+07</td>\n",
       "      <td>-2.157243e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>1.518294e+08</td>\n",
       "      <td>2.449999e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>6.607978e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          REVENUE          COGS    PREPAYMENT   OTH_PAYABLE  C_INF_FR_FINAN_A  \\\n",
       "0    3.680000e+11  2.350000e+11  9.779583e+10  3.847734e+10      1.230000e+11   \n",
       "1    5.526091e+08  4.165185e+08  1.212854e+08  2.388671e+08      6.445931e+08   \n",
       "2    3.731330e+09  2.044318e+09  1.043950e+08  6.491167e+08      1.919280e+09   \n",
       "3    4.202084e+07  1.316892e+07  3.039000e+04  3.293226e+07      1.300000e+07   \n",
       "4    1.893071e+09  1.443554e+09  4.754241e+07  2.857902e+08      8.178834e+08   \n",
       "..            ...           ...           ...           ...               ...   \n",
       "623  1.738004e+08  7.289600e+06  4.289913e+06  7.362868e+07      1.045188e+09   \n",
       "624  5.045575e+08  3.329071e+08  3.766541e+06  3.293226e+07      2.727550e+07   \n",
       "625  3.351035e+08  2.018895e+08  3.238091e+06  3.293226e+07      1.500000e+08   \n",
       "626  2.584064e+08  1.426508e+08  1.814436e+06  3.293226e+07      4.135000e+07   \n",
       "627  7.738161e+08  5.556131e+08  1.774841e+06  3.254897e+07      2.708759e+08   \n",
       "\n",
       "     SURPLUS_RESER  C_FR_OTH_INVEST_A         T_NCA       OTH_NCA  \\\n",
       "0     7.082625e+10       8.177287e+09  2.910000e+11  9.107320e+09   \n",
       "1     1.495191e+08       8.800000e+07  1.434297e+09  2.518367e+07   \n",
       "2     1.797479e+09       1.469453e+08  3.269382e+09  1.645932e+09   \n",
       "3     8.998898e+06       1.551102e+08  1.421271e+08  4.445534e+07   \n",
       "4     8.592789e+06       1.085256e+08  7.193082e+08  3.300000e+07   \n",
       "..             ...                ...           ...           ...   \n",
       "623   5.236093e+06       6.838826e+08  6.191922e+08  3.251840e+07   \n",
       "624   1.388311e+07       2.586743e+08  1.054024e+08  2.394196e+06   \n",
       "625   2.565213e+07       1.529137e+08  1.992412e+07  5.000000e+04   \n",
       "626   9.019362e+06       2.370000e+08  8.756340e+07  5.710999e+07   \n",
       "627   1.938591e+07       1.870351e+08  4.039975e+08  1.225751e+07   \n",
       "\n",
       "     MINORITY_GAIN  END_DATE_REP  RETAINED_EARNINGS      SELL_EXP  \\\n",
       "0     1.625953e+10             7       9.535204e+10  9.044497e+09   \n",
       "1     3.810302e+06             7      -1.440113e+08  1.050584e+07   \n",
       "2     4.190187e+07             7       3.103787e+09  5.173622e+07   \n",
       "3    -5.844119e+04             7      -2.656718e+08  1.640569e+06   \n",
       "4     7.965270e+07             7      -1.857507e+09  5.032299e+06   \n",
       "..             ...           ...                ...           ...   \n",
       "623   1.790444e+06             7      -2.173116e+07  7.354806e+07   \n",
       "624   2.167739e+06             7       1.684488e+08  1.467520e+07   \n",
       "625   1.749893e+06             7       1.886917e+08  4.395137e+06   \n",
       "626  -9.074536e+05             7       7.441286e+07  8.008995e+06   \n",
       "627  -2.157243e+06             7       1.518294e+08  2.449999e+07   \n",
       "\n",
       "     PUBLISH_DATE        T_LIAB  \n",
       "0               7  1.460000e+12  \n",
       "1               7  1.289555e+09  \n",
       "2               7  8.575092e+09  \n",
       "3               7  3.208891e+08  \n",
       "4               7  3.537930e+09  \n",
       "..            ...           ...  \n",
       "623             7  2.450958e+08  \n",
       "624             7  3.988528e+08  \n",
       "625             7  7.945696e+07  \n",
       "626             7  7.341945e+07  \n",
       "627             7  6.607978e+08  \n",
       "\n",
       "[628 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ct_pred[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用模型\n",
    "import joblib\n",
    "model2=joblib.load(\"stacking_ct_0.16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Pred(model2.predict_proba(df_ct_pred[ct])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_ct_pred['FLAG'] = Pred(model2.predict_proba(df_ct_pred[ct])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct_pred['FLAG'] = Pred(model2.predict_proba(df_ct_pred[ct])[:,1])\n",
    "df_ct_pred.to_csv(r'./PRED_ct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct_pred=pd.read_csv(r'./pre_data_ct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_ct_same_proba=sclf.predict_proba(df_ct_pred[ct])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[19:17:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5400916380297823\n",
      "auc is 0.5148911798396335\n",
      "[19:17:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "stacking model\n",
      "auc is 0.5193227824806772\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "\n",
    "\n",
    "x = df_ct[ct1]\n",
    "y = df_ct['FLAG']\n",
    "\n",
    "# 划分数据集&SMOTE采样\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=512)\n",
    "from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "smo = SMOTE()\n",
    "X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=0.5,reg_alpha=1.7,reg_lambda=0.5)\n",
    "m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)\n",
    "\n",
    "models = [m_xgb,m_clf]\n",
    "\n",
    "print('base model (m_xgb & m_clf)')\n",
    "for model in models:\n",
    "    model.fit(X_smo, y_smo)\n",
    "    pred = model.predict(x_test)\n",
    "    print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "sclf.fit(X_smo, y_smo)\n",
    "pred = sclf.predict(x_test)\n",
    "\n",
    "print('stacking model')\n",
    "print(\"auc is {}\".format(roc_auc_score(pred, y_test)))\n",
    "plt.scatter(np.arange(len(pred)), pred)\n",
    "plt.plot(np.arange(len(y_test)), y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_ct_dif_proba=sclf.predict_proba(df_ct_pred[ct1])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct_proba = (3/4)*df_ct_dif_proba+(1/4)*df_ct_same_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.74782   ,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.74782   , 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.74782   ,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.25030336, 0.00165417, 0.00165417, 0.00165417, 0.74782   ,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.25030336, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.74782   , 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.74782   , 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.74782   ,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.25030336, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.74782   , 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.9964692 , 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.9964692 , 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.74782   , 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.74782   , 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.74782   , 0.00165417,\n",
       "       0.00165417, 0.00165417, 0.00165417, 0.00165417, 0.00165417,\n",
       "       0.00165417], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ct_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 共有特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[21:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4746588693957115\n",
      "auc is 0.5083820662768032\n",
      "[21:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 1\n",
      "base model (m_xgb & m_clf)\n",
      "[21:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5785575048732943\n",
      "auc is 0.4859649122807017\n",
      "[21:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 2\n",
      "base model (m_xgb & m_clf)\n",
      "[21:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4766081871345029\n",
      "auc is 0.5025341130604288\n",
      "[21:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 3\n",
      "base model (m_xgb & m_clf)\n",
      "[21:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5736842105263158\n",
      "auc is 0.5171539961013645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 4\n",
      "base model (m_xgb & m_clf)\n",
      "[21:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47953216374269003\n",
      "auc is 0.49766081871345025\n",
      "[21:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 5\n",
      "base model (m_xgb & m_clf)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47855750487329435\n",
      "auc is 0.49766081871345025\n",
      "[21:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 6\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5766081871345029\n",
      "auc is 0.5054580896686159\n",
      "[21:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 7\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47855750487329435\n",
      "auc is 0.5035087719298246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 8\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47758284600389866\n",
      "auc is 0.5064327485380117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 9\n",
      "base model (m_xgb & m_clf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4766081871345029\n",
      "auc is 0.5044834307992202\n",
      "[21:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 10\n",
      "base model (m_xgb & m_clf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4824561403508772\n",
      "auc is 0.5025341130604288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 11\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47855750487329435\n",
      "auc is 0.5035087719298246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 12\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.48050682261208577\n",
      "auc is 0.5093567251461988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 13\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5746588693957114\n",
      "auc is 0.5005847953216375\n",
      "[21:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 14\n",
      "base model (m_xgb & m_clf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5727095516569201\n",
      "auc is 0.49181286549707603\n",
      "[21:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 15\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4766081871345029\n",
      "auc is 0.5005847953216375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 16\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4727095516569201\n",
      "auc is 0.5044834307992202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 17\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4766081871345029\n",
      "auc is 0.5054580896686159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 18\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.4746588693957115\n",
      "auc is 0.5820662768031188\n",
      "[21:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 19\n",
      "base model (m_xgb & m_clf)\n",
      "[21:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.47953216374269003\n",
      "auc is 0.5132553606237816\n",
      "[21:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "h= 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from sklearn import metrics\n",
    "h=0\n",
    "for i in range(20):\n",
    "    \n",
    "    x = df_fw[fw]\n",
    "    y = df_fw['FLAG']\n",
    "    \n",
    "    # 划分数据集&SMOTE采样\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=202)\n",
    "    from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "    smo = SMOTE()\n",
    "    X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "    m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=1.5,reg_alpha=0.7,reg_lambda=0.5)\n",
    "    m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)#)\n",
    "    models = [m_xgb,m_clf]\n",
    "\n",
    "    print('base model (m_xgb & m_clf)')\n",
    "    for model in models:\n",
    "        model.fit(X_smo, y_smo)\n",
    "        pred = model.predict(x_test)\n",
    "        print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "    sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "    sclf.fit(X_smo, y_smo)\n",
    "    pred = sclf.predict(x_test)\n",
    "    \n",
    "    if metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test)>0.05:\n",
    "        print(metrics.recall_score(Pred(sclf.predict_proba(x_test)[:,1]),y_test))\n",
    "        break\n",
    "    else:\n",
    "        h=h+1\n",
    "        print(\"h=\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stacking_fw_0.08']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sclf,\"stacking_fw_0.08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zz_pred=pd.read_csv(r'./pre_data_zz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用模型\n",
    "import joblib\n",
    "model4=joblib.load(\"stacking_model_0.136\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Pred(model4.predict_proba(df_zz_pred[o])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_zz_pred['FLAG'] = Pred(model4.predict_proba(df_zz_pred[o])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zz_pred.to_csv(r'./PRED_zz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=['REVENUE', 'COGS', 'PREPAYMENT', 'OTH_PAYABLE', 'C_INF_FR_FINAN_A',\n",
    "       'SURPLUS_RESER', 'C_FR_OTH_INVEST_A', 'T_NCA', 'OTH_NCA',\n",
    "       'MINORITY_GAIN', 'END_DATE_REP', 'RETAINED_EARNINGS', 'SELL_EXP',\n",
    "       'PUBLISH_DATE', 'T_LIAB','T_COGS', 'T_PROFIT', 'T_COMPR_INCOME',\n",
    "       'OPERATE_PROFIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pred(x):\n",
    "    u=[]\n",
    "    for i in x:\n",
    "        if i>0.1:\n",
    "            u.append(1)\n",
    "        else:\n",
    "            u.append(0)\n",
    "    return np.array(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[19:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.547945205479452\n",
      "auc is 0.5792563600782779\n",
      "[19:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:23:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "stacking model\n",
      "auc is 0.547945205479452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "\n",
    "\n",
    "x = df_fw[fw]\n",
    "y = df_fw['FLAG']\n",
    "\n",
    "# 划分数据集&SMOTE采样\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=315)\n",
    "from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "smo = SMOTE()\n",
    "X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=0.5,reg_alpha=2.7,reg_lambda=0.5)\n",
    "m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)\n",
    "\n",
    "models = [m_xgb,m_clf]\n",
    "\n",
    "print('base model (m_xgb & m_clf)')\n",
    "for model in models:\n",
    "    model.fit(X_smo, y_smo)\n",
    "    pred = model.predict(x_test)\n",
    "    print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "sclf.fit(X_smo, y_smo)\n",
    "pred = sclf.predict(x_test)\n",
    "\n",
    "print('stacking model')\n",
    "print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "plt.scatter(np.arange(len(pred)), pred)\n",
    "plt.plot(np.arange(len(y_test)), y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fw_pred=pd.read_csv(r'./pre_data_fw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_fw_same_proba=sclf.predict_proba(df_fw_pred[fw])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 特有特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model (m_xgb & m_clf)\n",
      "[19:25:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc is 0.5628255208333334\n",
      "auc is 0.7369791666666667\n",
      "[19:25:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:25:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "stacking model\n",
      "auc is 0.5628255208333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier as XGBC\n",
    "\n",
    "\n",
    "x = df_fw[fw1]\n",
    "y = df_fw['FLAG']\n",
    "\n",
    "# 划分数据集&SMOTE采样\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=666)\n",
    "from imblearn.over_sampling import SMOTE#df1_full[b]\n",
    "smo = SMOTE()\n",
    "X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "\n",
    "m_xgb = XGBC(n_estimators=200,max_depth=4,learning_rate=0.3,gamma=0.5,reg_alpha=2.7,reg_lambda=0.5)\n",
    "m_clf = RandomForestClassifier(n_estimators=28,max_depth=4,max_features=8,max_leaf_nodes=20)\n",
    "\n",
    "models = [m_xgb,m_clf]\n",
    "\n",
    "print('base model (m_xgb & m_clf)')\n",
    "for model in models:\n",
    "    model.fit(X_smo, y_smo)\n",
    "    pred = model.predict(x_test)\n",
    "    print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "sclf = StackingClassifier(classifiers=models,meta_classifier=m_xgb)\n",
    "sclf.fit(X_smo, y_smo)\n",
    "pred = sclf.predict(x_test)\n",
    "\n",
    "print('stacking model')\n",
    "print(\"auc is {}\".format(roc_auc_score(y_test, pred)))\n",
    "plt.scatter(np.arange(len(pred)), pred)\n",
    "plt.plot(np.arange(len(y_test)), y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_fw_dif_proba=sclf.predict_proba(df_fw_pred[fw1])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fw_proba = (3/4)*df_fw_dif_proba+(1/4)*df_fw_same_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.74356467, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.99102515, 0.99102515,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.25006893,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.74356467, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.74356467,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.25006893, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.74356467, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.74356467, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.74356467, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.74356467, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.25006893, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.74356467, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.74356467, 0.00260846, 0.00260846, 0.74356467, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.25006893, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.74356467, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.74356467, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.74356467, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.74356467, 0.00260846, 0.00260846,\n",
       "       0.00260846, 0.00260846, 0.00260846, 0.00260846, 0.00260846],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fw_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 各产业共有特征、特有特征预测概率加权求和 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_res(x):\n",
    "    df__result = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i] >0.5:\n",
    "            df__result.append(1)\n",
    "        else:\n",
    "            df__result.append(0)\n",
    "    return np.array(df__result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_result = pred_res(df_wy_proba)\n",
    "df_ct_result = pred_res(df_ct_proba)\n",
    "df_fw_result = pred_res(df_fw_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_pred['FLAG']=df_wy_result\n",
    "df_ct_pred['FLAG']=df_ct_result\n",
    "df_fw_pred['FLAG']=df_fw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wy_pred.to_csv(r'./WY_PRED_RESULT.csv')\n",
    "df_ct_pred.to_csv(r'./CT_PRED_RESULT.csv')\n",
    "df_fw_pred.to_csv(r'./FW_PRED_RESULT.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
